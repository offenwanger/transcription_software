This code has been adapted from the vosk API examples: 
https://github.com/alphacep/vosk-api

The models have been downloaded from 
https://alphacephei.com/vosk/models

To use this software:
- install vosk, ensure the demos are working. 
- download the repository
- convert your audio to WAV, and place it in the main folder next to main.py titled full_recording.wav. 
- extract about 30 sections of speech for each speaker, save these files as speaker1.wav and speaker2.wav
- run main.py. 
- It should generate trainscript.html
